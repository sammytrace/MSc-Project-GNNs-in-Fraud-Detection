{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","mount_file_id":"1KmArMfc5lp3Idz42xJNjIO8HKF9tEzSZ","authorship_tag":"ABX9TyMtpXCvKMVMGYVEBdeuIo7i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["#### **Install necessary Libraries**"],"metadata":{"id":"yPzd5qSYzNCB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4KaP8fYVr8RQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735927764300,"user_tz":180,"elapsed":11658,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"ed91dc24-a792-4510-fbcf-fe25fc40cef7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cpu)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiohttp (from torch-geometric)\n","  Downloading aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\n","Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch-geometric)\n","  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n","Collecting aiosignal>=1.1.2 (from aiohttp->torch-geometric)\n","  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n","Collecting async-timeout<6.0,>=4.0 (from aiohttp->torch-geometric)\n","  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.3.0)\n","Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n","  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n","  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n","Collecting propcache>=0.2.0 (from aiohttp->torch-geometric)\n","  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n","Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch-geometric)\n","  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n","Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n","Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n","Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: propcache, multidict, frozenlist, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch-geometric\n","Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 async-timeout-5.0.1 frozenlist-1.5.0 multidict-6.1.0 propcache-0.2.1 torch-geometric-2.6.1 yarl-1.18.3\n","/bin/bash: line 1: YOUR-TORCH-VERSION: No such file or directory\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cpu)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cpu)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cpu)\n","Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.11)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.12.14)\n"]}],"source":["!pip install torch\n","!pip install torch-geometric\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-<YOUR-TORCH-VERSION>+cpu.html\n","!pip install torch torchvision torchaudio torch_geometric"]},{"cell_type":"markdown","source":["#### **Import the required Libraries**"],"metadata":{"id":"ON1LGqWV8ti1"}},{"cell_type":"code","source":["import torch                                      # The main PyTorch library for tensor computation.\n","import torch.nn as nn                             # Provides classes and functions for building neural networks.\n","import torch.optim as optim                       # Contains various optimization algorithms for training neural networks.\n","from torch_geometric.nn import GCNConv            # A Graph Convolutional Layer from PyTorch Geometric.\n","from torch_geometric.nn import GATConv            # A Graph Attention Network (GAT) Convolutional Layer from PyTorch Geometric.\n","from torch_geometric.nn import SAGEConv           # A GraphSAGE Convolutional Layer from PyTorch Geometric.\n","from torch_geometric.nn import TransformerConv    # A Transformer Convolutional Layer from PyTorch Geometric.\n","import torch.nn.functional as F                   # Contains various functions for building neural networks (e.g., activation functions).\n","from torch_geometric.data import Data             # A class for graph data in PyTorch Geometric.\n","from torch.optim import Adam                      # Adam optimization algorithm for training neural networks.\n","from torch.nn.functional import cross_entropy     # Cross-entropy loss function for classification tasks.\n","from torch_geometric.loader import NeighborLoader # Loads graph data with neighbor sampling for efficient training.\n","from torch_geometric.loader import DataLoader     # A DataLoader for graph data in PyTorch Geometric.\n","import networkx as nx                             # Library for graph and network analysis.\n","from torch_geometric.utils import from_networkx   # Converts a NetworkX graph to PyTorch Geometric format.\n","from torch_geometric.utils import subgraph        # Extracts a subgraph from a larger graph.\n","from sklearn.preprocessing import StandardScaler  # Standardizes features by removing the mean and scaling to unit variance.\n","from sklearn.model_selection import train_test_split # Splits datasets into training and testing subsets.\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score # Metrics for evaluating models.\n","from tqdm import tqdm                             # For progress tracking in loops.\n","import networkx as nx                             # Library for creating and analyzing graph data structures.\n","import pickle                                     # For saving and loading Python objects (e.g., models, data).\n","import os                                         # For file and directory operations.\n","import itertools                                  # For working with iterators and combinations.\n","from itertools import product                     # For generating the Cartesian product of input iterables.\n","# Import python packages\n","import pandas as pd                               # For data manipulation and analysis.\n","import numpy as np                                # For numerical computations.\n","import seaborn as sns                             # For data visualization.\n","import matplotlib.pyplot as plt                   # For creating visualizations.\n","# To ignore warnings\n","import warnings                                   # Handles Python warnings.\n","warnings.filterwarnings(\"ignore\")                # Suppresses all warnings.\n"],"metadata":{"id":"NKPaE-8m1B-N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Load Node data and convert to pickle**"],"metadata":{"id":"m5TTD40PFKVo"}},{"cell_type":"code","source":["# Load the resampled data from CSV\n","graph_data = pd.read_csv('/content/drive/MyDrive/GraphFeatures/graph_data.csv')\n","\n","# Assuming node_data is created as a copy of graph_data\n","node_data = graph_data.copy()\n","\n","# Define the file path in Google Drive\n","node_data_file_path = '/content/drive/MyDrive/GraphFeatures/node_data.pkl'\n","\n","# Save node_data as a pickle file\n","with open(node_data_file_path, 'wb') as f:\n","    pickle.dump(node_data, f)\n","\n","print(f\"node_data saved successfully to {node_data_file_path}!\")\n"],"metadata":{"id":"2SN1Fm2mFP3_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732970913243,"user_tz":180,"elapsed":3224,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"c06bc0e8-a059-4435-a576-a7d9c31f2568"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["node_data saved successfully to /content/drive/MyDrive/GraphFeatures/node_data.pkl!\n"]}]},{"cell_type":"markdown","source":["#### **Load Node-Centric Graph and Node_Data**"],"metadata":{"id":"EgXJOmsvMrQl"}},{"cell_type":"code","source":["# Load the saved node-centric graph\n","with open('/content/drive/MyDrive/GraphFeatures/NodeCentricGraph.pkl', 'rb') as f:\n","    G = pickle.load(f)\n","\n","# Define the file path in Google Drive\n","node_data_file_path = '/content/drive/MyDrive/GraphFeatures/node_data.pkl'\n","\n","# Load the node_data from the pickle file\n","with open(node_data_file_path, 'rb') as f:\n","    node_data = pickle.load(f)"],"metadata":{"id":"ZItz41e7RJnL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Convert the Node-Centric Graph to PyTorch Geometric Format**"],"metadata":{"id":"1JNdTre2-ILZ"}},{"cell_type":"code","source":["# Convert NetworkX graph to PyTorch Geometric data\n","data = from_networkx(G)\n","\n","# Extract target labels (isFraud) and ensure data type consistency\n","data.y = torch.tensor(\n","    [node_data.loc[node_data['TransactionID'] == node, 'isFraud'].values[0]\n","     for node in G.nodes],\n","    dtype=torch.long  # Ensure labels are integers for classification\n",")\n","\n","# Extract node features and ensure consistent dtype\n","data.x = torch.tensor(\n","    [list(G.nodes[node].values()) for node in G.nodes],\n","    dtype=torch.float  # Features should be float for GNN layers\n",")"],"metadata":{"id":"0ChQTXHecXSq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Scale Node Features**"],"metadata":{"id":"1o0vdLG6UwkQ"}},{"cell_type":"code","source":["# Scale node features and maintain consistent dtype\n","scaler = StandardScaler()\n","data.x = torch.tensor(\n","    scaler.fit_transform(data.x.numpy()),\n","    dtype=torch.float  # Ensure consistent dtype after scaling\n",")"],"metadata":{"id":"WRahs_DTcaTw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Train Test Split**"],"metadata":{"id":"GV8ycDCGZrLq"}},{"cell_type":"code","source":["# Split the data into train and temporary (validation + test) sets\n","train_indices, temp_indices = train_test_split(\n","    range(data.num_nodes),\n","    test_size=0.4,  # 40% will be split further into validation and test sets\n","    random_state=42\n",")\n","\n","# Further split the temporary set into validation and test sets\n","val_indices, test_indices = train_test_split(\n","    temp_indices,\n","    test_size=0.5,  # Half of the remaining 40% (20% of total) for test\n","    random_state=42\n",")\n","\n","# Create boolean masks for train, validation, and test sets\n","data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n","data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n","data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n","\n","data.train_mask[train_indices] = True\n","data.val_mask[val_indices] = True\n","data.test_mask[test_indices] = True\n","\n","# Print the number of nodes in each split\n","print(f\"Train nodes: {data.train_mask.sum().item()}\")\n","print(f\"Validation nodes: {data.val_mask.sum().item()}\")\n","print(f\"Test nodes: {data.test_mask.sum().item()}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_x_fV4f6Seju","executionInfo":{"status":"ok","timestamp":1735929067193,"user_tz":180,"elapsed":283,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"f9d54fd2-2026-43fc-897a-af461b8b8beb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train nodes: 59938\n","Validation nodes: 19980\n","Test nodes: 19980\n"]}]},{"cell_type":"markdown","source":["#### **Node-Centric Graph with Graph Convolution Network (GCN) Model**"],"metadata":{"id":"qLbUhg3O2OdN"}},{"cell_type":"markdown","source":["##### **Define the Model**"],"metadata":{"id":"BFBNyxyAI9nh"}},{"cell_type":"code","source":["class GCNModel(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GCNModel, self).__init__()\n","        self.conv1 = GCNConv(input_dim, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, output_dim)\n","\n","    def forward(self, x, edge_index):\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n"],"metadata":{"id":"YxKJzPqOJBXi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Initialize and Train the Model**"],"metadata":{"id":"U-yXdKtRJ_qF"}},{"cell_type":"code","source":["# Model parameters\n","input_dim = data.x.size(1)  # Feature dimension\n","hidden_dim = 32\n","output_dim = len(torch.unique(data.y))  # Number of classes\n","\n","# Initialize the model, optimizer, and loss function\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = GCNModel(input_dim, hidden_dim, output_dim).to(device)\n","data = data.to(device)\n","optimizer = Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Training loop\n","num_epochs = 50\n","best_val_loss = float('inf')\n","patience = 5\n","early_stop_counter = 0\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data.x, data.edge_index)\n","    train_loss = criterion(out[data.train_mask], data.y[data.train_mask])\n","    train_loss.backward()\n","    optimizer.step()\n","\n","    # Validation phase\n","    model.eval()\n","    with torch.no_grad():\n","        val_out = model(data.x, data.edge_index)\n","        val_loss = criterion(val_out[data.val_mask], data.y[data.val_mask])\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n","\n","    # Early stopping logic\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        early_stop_counter = 0\n","    else:\n","        early_stop_counter += 1\n","        if early_stop_counter >= patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n"],"metadata":{"id":"C0RVh-NwKDgz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735929376503,"user_tz":180,"elapsed":298226,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"38293154-47f6-4d3c-ee52-75a2e6471f56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Train Loss: 0.7191, Val Loss: 0.6710\n","Epoch 2/50, Train Loss: 0.6693, Val Loss: 0.6705\n","Epoch 3/50, Train Loss: 0.6698, Val Loss: 0.6623\n","Epoch 4/50, Train Loss: 0.6624, Val Loss: 0.6612\n","Epoch 5/50, Train Loss: 0.6617, Val Loss: 0.6570\n","Epoch 6/50, Train Loss: 0.6574, Val Loss: 0.6506\n","Epoch 7/50, Train Loss: 0.6506, Val Loss: 0.6516\n","Epoch 8/50, Train Loss: 0.6513, Val Loss: 0.6553\n","Epoch 9/50, Train Loss: 0.6548, Val Loss: 0.6552\n","Epoch 10/50, Train Loss: 0.6547, Val Loss: 0.6521\n","Epoch 11/50, Train Loss: 0.6517, Val Loss: 0.6495\n","Epoch 12/50, Train Loss: 0.6492, Val Loss: 0.6485\n","Epoch 13/50, Train Loss: 0.6484, Val Loss: 0.6476\n","Epoch 14/50, Train Loss: 0.6475, Val Loss: 0.6469\n","Epoch 15/50, Train Loss: 0.6468, Val Loss: 0.6476\n","Epoch 16/50, Train Loss: 0.6475, Val Loss: 0.6492\n","Epoch 17/50, Train Loss: 0.6489, Val Loss: 0.6496\n","Epoch 18/50, Train Loss: 0.6493, Val Loss: 0.6483\n","Epoch 19/50, Train Loss: 0.6480, Val Loss: 0.6466\n","Epoch 20/50, Train Loss: 0.6464, Val Loss: 0.6458\n","Epoch 21/50, Train Loss: 0.6457, Val Loss: 0.6459\n","Epoch 22/50, Train Loss: 0.6459, Val Loss: 0.6461\n","Epoch 23/50, Train Loss: 0.6461, Val Loss: 0.6460\n","Epoch 24/50, Train Loss: 0.6459, Val Loss: 0.6459\n","Epoch 25/50, Train Loss: 0.6458, Val Loss: 0.6460\n","Early stopping at epoch 25\n"]}]},{"cell_type":"markdown","source":["##### **Evaluate the GCN Model**"],"metadata":{"id":"dYRgqZy6O2ow"}},{"cell_type":"code","source":["# Evaluation function\n","def evaluate_model(model, data):\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data.x, data.edge_index)\n","        preds = out.argmax(dim=1)  # Predicted labels\n","\n","        # Test set metrics\n","        y_true = data.y[data.test_mask].cpu().numpy()\n","        y_pred = preds[data.test_mask].cpu().numpy()\n","\n","        accuracy = accuracy_score(y_true, y_pred)\n","        precision = precision_score(y_true, y_pred, zero_division=0)\n","        recall = recall_score(y_true, y_pred, zero_division=0)\n","        f1 = f1_score(y_true, y_pred, zero_division=0)\n","        auc_roc = roc_auc_score(y_true, out[data.test_mask][:, 1].cpu().numpy())\n","\n","        print(\"Test Metrics:\")\n","        print(f\"Accuracy: {accuracy:.4f}\")\n","        print(f\"Precision: {precision:.4f}\")\n","        print(f\"Recall: {recall:.4f}\")\n","        print(f\"F1-Score: {f1:.4f}\")\n","        print(f\"AUC-ROC: {auc_roc:.4f}\")\n","\n","# Evaluate the trained model\n","evaluate_model(model, data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBC9McZwWtja","executionInfo":{"status":"ok","timestamp":1735929408052,"user_tz":180,"elapsed":4864,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"6c6d4fea-3bc7-40c7-9998-13833ff7963d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Metrics:\n","Accuracy: 0.6435\n","Precision: 0.7013\n","Recall: 0.5038\n","F1-Score: 0.5864\n","AUC-ROC: 0.6519\n"]}]},{"cell_type":"markdown","source":["#### **Node-Centric Graph with GAT Model**"],"metadata":{"id":"Q2C2CGMrIDHn"}},{"cell_type":"markdown","source":["##### **Define GAT Model**"],"metadata":{"id":"c0a0dyASIP4f"}},{"cell_type":"code","source":["class GATModel(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_heads):\n","        super(GATModel, self).__init__()\n","        self.conv1 = GATConv(input_dim, hidden_dim, heads=num_heads, dropout=0.6)\n","        self.conv2 = GATConv(hidden_dim * num_heads, output_dim, heads=1, dropout=0.6)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = F.elu(x)  # Activation function\n","        x = F.dropout(x, p=0.6, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n"],"metadata":{"id":"vyZwG5-8JNbE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Initialize and Train GAT Model**"],"metadata":{"id":"zSblHOo9JTG_"}},{"cell_type":"code","source":["# Model parameters\n","input_dim = data.x.size(1)  # Feature dimension\n","hidden_dim = 32\n","output_dim = len(torch.unique(data.y))  # Number of classes\n","num_heads = 4\n","\n","# Initialize the model, optimizer, and loss function\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = GATModel(input_dim, hidden_dim, output_dim, num_heads).to(device)\n","data = data.to(device)\n","optimizer = Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Training loop\n","num_epochs = 50\n","best_val_loss = float('inf')\n","patience = 5\n","early_stop_counter = 0\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data.x, data.edge_index)\n","    train_loss = criterion(out[data.train_mask], data.y[data.train_mask])\n","    train_loss.backward()\n","    optimizer.step()\n","\n","    # Validation phase\n","    model.eval()\n","    with torch.no_grad():\n","        val_out = model(data.x, data.edge_index)\n","        val_loss = criterion(val_out[data.val_mask], data.y[data.val_mask])\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n","\n","    # Early stopping logic\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        early_stop_counter = 0\n","    else:\n","        early_stop_counter += 1\n","        if early_stop_counter >= patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E24asUYxJc0W","outputId":"4e1e572e-4511-4fe6-b065-66607bf8ae85","executionInfo":{"status":"ok","timestamp":1735930074364,"user_tz":180,"elapsed":651511,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Train Loss: 21.2482, Val Loss: 2.9551\n","Epoch 2/50, Train Loss: 10.8220, Val Loss: 3.1767\n","Epoch 3/50, Train Loss: 3.4737, Val Loss: 2.8836\n","Epoch 4/50, Train Loss: 1.9550, Val Loss: 1.4459\n","Epoch 5/50, Train Loss: 1.1774, Val Loss: 1.1910\n","Epoch 6/50, Train Loss: 1.1336, Val Loss: 1.0578\n","Epoch 7/50, Train Loss: 1.0314, Val Loss: 1.0151\n","Epoch 8/50, Train Loss: 0.9815, Val Loss: 0.9731\n","Epoch 9/50, Train Loss: 0.8813, Val Loss: 0.9434\n","Epoch 10/50, Train Loss: 0.8761, Val Loss: 0.9285\n","Epoch 11/50, Train Loss: 0.8369, Val Loss: 0.9321\n","Epoch 12/50, Train Loss: 0.8205, Val Loss: 0.9506\n","Epoch 13/50, Train Loss: 0.7906, Val Loss: 0.9869\n","Epoch 14/50, Train Loss: 0.8233, Val Loss: 1.0341\n","Epoch 15/50, Train Loss: 0.8408, Val Loss: 1.0443\n","Early stopping at epoch 15\n"]}]},{"cell_type":"markdown","source":["##### **Evaluate the Model**"],"metadata":{"id":"tZybzk9s5gp-"}},{"cell_type":"code","source":["# Evaluation function\n","def evaluate_model(model, data):\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data.x, data.edge_index)\n","        preds = out.argmax(dim=1)  # Predicted labels\n","\n","        # Test set metrics\n","        y_true = data.y[data.test_mask].cpu().numpy()\n","        y_pred = preds[data.test_mask].cpu().numpy()\n","\n","        accuracy = accuracy_score(y_true, y_pred)\n","        precision = precision_score(y_true, y_pred, zero_division=0)\n","        recall = recall_score(y_true, y_pred, zero_division=0)\n","        f1 = f1_score(y_true, y_pred, zero_division=0)\n","        auc_roc = roc_auc_score(y_true, out[data.test_mask][:, 1].cpu().numpy())\n","\n","        print(\"Test Metrics:\")\n","        print(f\"Accuracy: {accuracy:.4f}\")\n","        print(f\"Precision: {precision:.4f}\")\n","        print(f\"Recall: {recall:.4f}\")\n","        print(f\"F1-Score: {f1:.4f}\")\n","        print(f\"AUC-ROC: {auc_roc:.4f}\")\n","\n","# Evaluate the trained model\n","evaluate_model(model, data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojieqSsDJvw-","executionInfo":{"status":"ok","timestamp":1735930660641,"user_tz":180,"elapsed":14012,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"58ba0b18-66c6-4df2-eb21-82e489d632ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Metrics:\n","Accuracy: 0.6026\n","Precision: 0.6882\n","Recall: 0.3797\n","F1-Score: 0.4894\n","AUC-ROC: 0.6000\n"]}]},{"cell_type":"markdown","source":["#### **Node-Centric Graph with GraphSAGE Model**"],"metadata":{"id":"l7IXDOAKOx_X"}},{"cell_type":"markdown","source":["##### **Define the Model**"],"metadata":{"id":"dT7mIOtOVaHW"}},{"cell_type":"code","source":["class GraphSAGEModel(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GraphSAGEModel, self).__init__()\n","        self.conv1 = SAGEConv(input_dim, hidden_dim)\n","        self.conv2 = SAGEConv(hidden_dim, output_dim)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n"],"metadata":{"id":"-rqo8szWO45R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Initialize and Train the Model**"],"metadata":{"id":"26ljk0OOVgBl"}},{"cell_type":"code","source":["# Model parameters\n","input_dim = data.x.size(1)  # Feature dimension\n","hidden_dim = 32\n","output_dim = len(torch.unique(data.y))  # Number of classes\n","\n","# Initialize the model, optimizer, and loss function\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = GraphSAGEModel(input_dim, hidden_dim, output_dim).to(device)\n","data = data.to(device)\n","optimizer = Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Training loop\n","num_epochs = 50\n","best_val_loss = float('inf')\n","patience = 5\n","early_stop_counter = 0\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data.x, data.edge_index)\n","    train_loss = criterion(out[data.train_mask], data.y[data.train_mask])\n","    train_loss.backward()\n","    optimizer.step()\n","\n","    # Validation phase\n","    model.eval()\n","    with torch.no_grad():\n","        val_out = model(data.x, data.edge_index)\n","        val_loss = criterion(val_out[data.val_mask], data.y[data.val_mask])\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n","\n","    # Early stopping logic\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        early_stop_counter = 0\n","    else:\n","        early_stop_counter += 1\n","        if early_stop_counter >= patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z0-r7bjJVmAH","executionInfo":{"status":"ok","timestamp":1735931357025,"user_tz":180,"elapsed":679926,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"0343fd3d-9f40-4d75-d0e8-f6f3fe6a5c85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Train Loss: 0.7330, Val Loss: 0.6581\n","Epoch 2/50, Train Loss: 0.6653, Val Loss: 0.6342\n","Epoch 3/50, Train Loss: 0.6423, Val Loss: 0.6233\n","Epoch 4/50, Train Loss: 0.6324, Val Loss: 0.6121\n","Epoch 5/50, Train Loss: 0.6214, Val Loss: 0.6001\n","Epoch 6/50, Train Loss: 0.6103, Val Loss: 0.5871\n","Epoch 7/50, Train Loss: 0.5972, Val Loss: 0.5751\n","Epoch 8/50, Train Loss: 0.5850, Val Loss: 0.5660\n","Epoch 9/50, Train Loss: 0.5763, Val Loss: 0.5598\n","Epoch 10/50, Train Loss: 0.5709, Val Loss: 0.5551\n","Epoch 11/50, Train Loss: 0.5653, Val Loss: 0.5503\n","Epoch 12/50, Train Loss: 0.5626, Val Loss: 0.5449\n","Epoch 13/50, Train Loss: 0.5583, Val Loss: 0.5397\n","Epoch 14/50, Train Loss: 0.5507, Val Loss: 0.5353\n","Epoch 15/50, Train Loss: 0.5490, Val Loss: 0.5317\n","Epoch 16/50, Train Loss: 0.5454, Val Loss: 0.5286\n","Epoch 17/50, Train Loss: 0.5420, Val Loss: 0.5257\n","Epoch 18/50, Train Loss: 0.5401, Val Loss: 0.5231\n","Epoch 19/50, Train Loss: 0.5384, Val Loss: 0.5207\n","Epoch 20/50, Train Loss: 0.5340, Val Loss: 0.5183\n","Epoch 21/50, Train Loss: 0.5313, Val Loss: 0.5159\n","Epoch 22/50, Train Loss: 0.5294, Val Loss: 0.5136\n","Epoch 23/50, Train Loss: 0.5272, Val Loss: 0.5115\n","Epoch 24/50, Train Loss: 0.5240, Val Loss: 0.5096\n","Epoch 25/50, Train Loss: 0.5235, Val Loss: 0.5077\n","Epoch 26/50, Train Loss: 0.5219, Val Loss: 0.5058\n","Epoch 27/50, Train Loss: 0.5200, Val Loss: 0.5041\n","Epoch 28/50, Train Loss: 0.5181, Val Loss: 0.5025\n","Epoch 29/50, Train Loss: 0.5166, Val Loss: 0.5012\n","Epoch 30/50, Train Loss: 0.5135, Val Loss: 0.4999\n","Epoch 31/50, Train Loss: 0.5123, Val Loss: 0.4985\n","Epoch 32/50, Train Loss: 0.5129, Val Loss: 0.4972\n","Epoch 33/50, Train Loss: 0.5122, Val Loss: 0.4960\n","Epoch 34/50, Train Loss: 0.5118, Val Loss: 0.4946\n","Epoch 35/50, Train Loss: 0.5095, Val Loss: 0.4934\n","Epoch 36/50, Train Loss: 0.5090, Val Loss: 0.4921\n","Epoch 37/50, Train Loss: 0.5063, Val Loss: 0.4909\n","Epoch 38/50, Train Loss: 0.5073, Val Loss: 0.4897\n","Epoch 39/50, Train Loss: 0.5044, Val Loss: 0.4886\n","Epoch 40/50, Train Loss: 0.5057, Val Loss: 0.4875\n","Epoch 41/50, Train Loss: 0.5036, Val Loss: 0.4865\n","Epoch 42/50, Train Loss: 0.5033, Val Loss: 0.4855\n","Epoch 43/50, Train Loss: 0.5010, Val Loss: 0.4847\n","Epoch 44/50, Train Loss: 0.5008, Val Loss: 0.4838\n","Epoch 45/50, Train Loss: 0.5015, Val Loss: 0.4830\n","Epoch 46/50, Train Loss: 0.4984, Val Loss: 0.4823\n","Epoch 47/50, Train Loss: 0.4990, Val Loss: 0.4816\n","Epoch 48/50, Train Loss: 0.4989, Val Loss: 0.4809\n","Epoch 49/50, Train Loss: 0.4962, Val Loss: 0.4802\n","Epoch 50/50, Train Loss: 0.4960, Val Loss: 0.4795\n"]}]},{"cell_type":"markdown","source":["##### **Evaluate the Model**"],"metadata":{"id":"2s9dr2HaWIO2"}},{"cell_type":"code","source":["# Evaluation function\n","def evaluate_model(model, data):\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data.x, data.edge_index)\n","        preds = out.argmax(dim=1)  # Predicted labels\n","\n","        # Test set metrics\n","        y_true = data.y[data.test_mask].cpu().numpy()\n","        y_pred = preds[data.test_mask].cpu().numpy()\n","\n","        accuracy = accuracy_score(y_true, y_pred)\n","        precision = precision_score(y_true, y_pred, zero_division=0)\n","        recall = recall_score(y_true, y_pred, zero_division=0)\n","        f1 = f1_score(y_true, y_pred, zero_division=0)\n","        auc_roc = roc_auc_score(y_true, out[data.test_mask][:, 1].cpu().numpy())\n","\n","        print(\"Test Metrics:\")\n","        print(f\"Accuracy: {accuracy:.4f}\")\n","        print(f\"Precision: {precision:.4f}\")\n","        print(f\"Recall: {recall:.4f}\")\n","        print(f\"F1-Score: {f1:.4f}\")\n","        print(f\"AUC-ROC: {auc_roc:.4f}\")\n","\n","# Evaluate the trained model\n","evaluate_model(model, data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jseiOJtFWMP7","executionInfo":{"status":"ok","timestamp":1735931362817,"user_tz":180,"elapsed":5795,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"779a9384-2f60-43ee-b501-6160b6f0481e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Metrics:\n","Accuracy: 0.7788\n","Precision: 0.7691\n","Recall: 0.7988\n","F1-Score: 0.7837\n","AUC-ROC: 0.8550\n"]}]},{"cell_type":"markdown","source":["#### **Node-Centric Graph with Graphomer Transformer Model**"],"metadata":{"id":"Ym9VtcIOMzia"}},{"cell_type":"markdown","source":["#### **Define Model**"],"metadata":{"id":"Wb91qMmcPZwC"}},{"cell_type":"code","source":["class Graphormer(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_heads, dropout=0.1):\n","        super(Graphormer, self).__init__()\n","        self.conv1 = TransformerConv(input_dim, hidden_dim, heads=num_heads, dropout=dropout)\n","        self.conv2 = TransformerConv(hidden_dim * num_heads, output_dim, heads=1, dropout=dropout)\n","        self.dropout = dropout\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n"],"metadata":{"id":"0LsdLhg2Pc0U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Initialize and Train the Graphomer Model**"],"metadata":{"id":"8JdHojSgP-q3"}},{"cell_type":"code","source":["# Model parameters\n","input_dim = data.x.size(1)  # Number of input features\n","hidden_dim = 64  # Hidden layer dimension\n","output_dim = len(torch.unique(data.y))  # Number of classes\n","num_heads = 4  # Number of attention heads\n","\n","# Initialize the model, optimizer, and loss function\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Graphormer(input_dim, hidden_dim, output_dim, num_heads).to(device)\n","data = data.to(device)\n","optimizer = Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Training loop\n","num_epochs = 50\n","best_val_loss = float('inf')\n","patience = 5\n","stopping_counter = 0\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    out = model(data.x, data.edge_index)\n","    train_loss = criterion(out[data.train_mask], data.y[data.train_mask])\n","    train_loss.backward()\n","    optimizer.step()\n","\n","    # Validation phase\n","    model.eval()\n","    with torch.no_grad():\n","        val_out = model(data.x, data.edge_index)\n","        val_loss = criterion(val_out[data.val_mask], data.y[data.val_mask])\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n","\n","    # Early stopping logic\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        stopping_counter = 0\n","    else:\n","        stopping_counter += 1\n","        if stopping_counter >= patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MyNgPlxHdltg","executionInfo":{"status":"ok","timestamp":1735937189167,"user_tz":180,"elapsed":5826352,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"a281be60-f51c-4c32-8c1e-a30caf2ae61e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Train Loss: 0.8653, Val Loss: 0.8049\n","Epoch 2/50, Train Loss: 0.7990, Val Loss: 0.6858\n","Epoch 3/50, Train Loss: 0.6911, Val Loss: 0.6013\n","Epoch 4/50, Train Loss: 0.6014, Val Loss: 0.5715\n","Epoch 5/50, Train Loss: 0.5696, Val Loss: 0.5594\n","Epoch 6/50, Train Loss: 0.5594, Val Loss: 0.5528\n","Epoch 7/50, Train Loss: 0.5551, Val Loss: 0.5436\n","Epoch 8/50, Train Loss: 0.5465, Val Loss: 0.5310\n","Epoch 9/50, Train Loss: 0.5341, Val Loss: 0.5186\n","Epoch 10/50, Train Loss: 0.5202, Val Loss: 0.5191\n","Epoch 11/50, Train Loss: 0.5194, Val Loss: 0.5165\n","Epoch 12/50, Train Loss: 0.5163, Val Loss: 0.5112\n","Epoch 13/50, Train Loss: 0.5108, Val Loss: 0.5061\n","Epoch 14/50, Train Loss: 0.5058, Val Loss: 0.5001\n","Epoch 15/50, Train Loss: 0.4991, Val Loss: 0.4973\n","Epoch 16/50, Train Loss: 0.4964, Val Loss: 0.4909\n","Epoch 17/50, Train Loss: 0.4896, Val Loss: 0.4883\n","Epoch 18/50, Train Loss: 0.4872, Val Loss: 0.4877\n","Epoch 19/50, Train Loss: 0.4852, Val Loss: 0.4831\n","Epoch 20/50, Train Loss: 0.4792, Val Loss: 0.4773\n","Epoch 21/50, Train Loss: 0.4734, Val Loss: 0.4746\n","Epoch 22/50, Train Loss: 0.4710, Val Loss: 0.4715\n","Epoch 23/50, Train Loss: 0.4674, Val Loss: 0.4691\n","Epoch 24/50, Train Loss: 0.4642, Val Loss: 0.4679\n","Epoch 25/50, Train Loss: 0.4622, Val Loss: 0.4653\n","Epoch 26/50, Train Loss: 0.4577, Val Loss: 0.4608\n","Epoch 27/50, Train Loss: 0.4549, Val Loss: 0.4578\n","Epoch 28/50, Train Loss: 0.4520, Val Loss: 0.4556\n","Epoch 29/50, Train Loss: 0.4501, Val Loss: 0.4534\n","Epoch 30/50, Train Loss: 0.4459, Val Loss: 0.4502\n","Epoch 31/50, Train Loss: 0.4436, Val Loss: 0.4481\n","Epoch 32/50, Train Loss: 0.4425, Val Loss: 0.4466\n","Epoch 33/50, Train Loss: 0.4378, Val Loss: 0.4444\n","Epoch 34/50, Train Loss: 0.4368, Val Loss: 0.4427\n","Epoch 35/50, Train Loss: 0.4339, Val Loss: 0.4399\n","Epoch 36/50, Train Loss: 0.4324, Val Loss: 0.4373\n","Epoch 37/50, Train Loss: 0.4287, Val Loss: 0.4354\n","Epoch 38/50, Train Loss: 0.4267, Val Loss: 0.4331\n","Epoch 39/50, Train Loss: 0.4234, Val Loss: 0.4313\n","Epoch 40/50, Train Loss: 0.4205, Val Loss: 0.4287\n","Epoch 41/50, Train Loss: 0.4176, Val Loss: 0.4263\n","Epoch 42/50, Train Loss: 0.4155, Val Loss: 0.4238\n","Epoch 43/50, Train Loss: 0.4122, Val Loss: 0.4210\n","Epoch 44/50, Train Loss: 0.4094, Val Loss: 0.4183\n","Epoch 45/50, Train Loss: 0.4096, Val Loss: 0.4167\n","Epoch 46/50, Train Loss: 0.4058, Val Loss: 0.4148\n","Epoch 47/50, Train Loss: 0.4026, Val Loss: 0.4126\n","Epoch 48/50, Train Loss: 0.4010, Val Loss: 0.4112\n","Epoch 49/50, Train Loss: 0.3996, Val Loss: 0.4089\n","Epoch 50/50, Train Loss: 0.3955, Val Loss: 0.4086\n"]}]},{"cell_type":"markdown","source":["#### **Evaluate the Model**"],"metadata":{"id":"RKNvWPUJRARz"}},{"cell_type":"code","source":["# Evaluation function\n","def evaluate_model(model, data):\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data.x, data.edge_index)\n","        preds = out.argmax(dim=1)  # Predicted labels\n","\n","        # Extract test set metrics\n","        y_true = data.y[data.test_mask].cpu().numpy()\n","        y_pred = preds[data.test_mask].cpu().numpy()\n","\n","        accuracy = accuracy_score(y_true, y_pred)\n","        precision = precision_score(y_true, y_pred, zero_division=0)\n","        recall = recall_score(y_true, y_pred, zero_division=0)\n","        f1 = f1_score(y_true, y_pred, zero_division=0)\n","        auc_roc = roc_auc_score(y_true, out[data.test_mask][:, 1].cpu().numpy())\n","\n","        print(\"Test Set Metrics:\")\n","        print(f\"Accuracy: {accuracy:.4f}\")\n","        print(f\"Precision: {precision:.4f}\")\n","        print(f\"Recall: {recall:.4f}\")\n","        print(f\"F1-Score: {f1:.4f}\")\n","        print(f\"AUC-ROC: {auc_roc:.4f}\")\n","\n","# Evaluate the trained model\n","evaluate_model(model, data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZCw6fFgFlL49","executionInfo":{"status":"ok","timestamp":1735937225121,"user_tz":180,"elapsed":35958,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"892959a2-cea2-4efa-ab6c-5eab132b8afe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Set Metrics:\n","Accuracy: 0.8240\n","Precision: 0.8264\n","Recall: 0.8216\n","F1-Score: 0.8240\n","AUC-ROC: 0.9014\n"]}]}]}