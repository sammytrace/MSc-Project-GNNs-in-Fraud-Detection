{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","mount_file_id":"1TMykdZst4AI_Ds7FWqjgZ-Sf6ihUM01-","authorship_tag":"ABX9TyNtt4wKOIcxHGF75/3pCXhC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["#### **Install Libraries**"],"metadata":{"id":"Rirnfz6pg4Pj"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzlusJg7aAKd","executionInfo":{"status":"ok","timestamp":1736019649995,"user_tz":180,"elapsed":9592,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"193449d5-65de-40f5-9147-4ebc20ef2375"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cpu)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiohttp (from torch-geometric)\n","  Downloading aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\n","Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch-geometric)\n","  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n","Collecting aiosignal>=1.1.2 (from aiohttp->torch-geometric)\n","  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n","Collecting async-timeout<6.0,>=4.0 (from aiohttp->torch-geometric)\n","  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.3.0)\n","Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n","  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n","  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n","Collecting propcache>=0.2.0 (from aiohttp->torch-geometric)\n","  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n","Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch-geometric)\n","  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n","Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n","Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n","Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: propcache, multidict, frozenlist, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch-geometric\n","Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 async-timeout-5.0.1 frozenlist-1.5.0 multidict-6.1.0 propcache-0.2.1 torch-geometric-2.6.1 yarl-1.18.3\n","/bin/bash: line 1: YOUR-TORCH-VERSION: No such file or directory\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cpu)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cpu)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cpu)\n","Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.11)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.12.14)\n"]}],"source":["!pip install torch\n","!pip install torch-geometric\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-<YOUR-TORCH-VERSION>+cpu.html\n","!pip install torch torchvision torchaudio torch_geometric"]},{"cell_type":"markdown","source":["#### **Import required Libraries**"],"metadata":{"id":"e51R4CGJhY6Y"}},{"cell_type":"code","source":["import torch                                      # The main PyTorch library for tensor computation.\n","import torch.nn as nn                             # Provides classes and functions for building neural networks.\n","import torch.optim as optim                       # Contains various optimization algorithms for training neural networks.\n","from torch_geometric.nn import GCNConv            # A Graph Convolutional Layer from PyTorch Geometric.\n","from torch_geometric.nn import GATConv            # A Graph Attention Network (GAT) Convolutional Layer from PyTorch Geometric.\n","from torch_geometric.nn import SAGEConv           # A GraphSAGE Convolutional Layer from PyTorch Geometric.\n","from torch_geometric.nn import TransformerConv    # A Transformer Convolutional Layer from PyTorch Geometric.\n","import torch.nn.functional as F                   # Contains various functions for building neural networks (e.g., activation functions).\n","from torch_geometric.data import Data             # A class for graph data in PyTorch Geometric.\n","from torch.optim import Adam                      # Adam optimization algorithm for training neural networks.\n","from torch.nn.functional import cross_entropy     # Cross-entropy loss function for classification tasks.\n","from torch_geometric.loader import NeighborLoader # Loads graph data with neighbor sampling for efficient training.\n","from torch_geometric.loader import DataLoader     # A DataLoader for graph data in PyTorch Geometric.\n","import networkx as nx                             # Library for graph and network analysis.\n","from torch_geometric.utils import from_networkx   # Converts a NetworkX graph to PyTorch Geometric format.\n","from sklearn.preprocessing import StandardScaler  # Standardizes features by removing the mean and scaling to unit variance.\n","from sklearn.model_selection import train_test_split # Splits datasets into training and testing subsets.\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score # Metrics for evaluating models.\n","from tqdm import tqdm                             # For progress tracking in loops.\n","import networkx as nx                             # Library for creating and analyzing graph data structures.\n","import pickle                                     # For saving and loading Python objects (e.g., models, data).\n","import os                                         # For file and directory operations.\n","import itertools                                  # For working with iterators and combinations.\n","from itertools import product                     # For generating the Cartesian product of input iterables.\n","# Import python packages\n","import pandas as pd                               # For data manipulation and analysis.\n","import numpy as np                                # For numerical computations.\n","import seaborn as sns                             # For data visualization.\n","import matplotlib.pyplot as plt                   # For creating visualizations.\n","# To ignore warnings\n","import warnings                                   # Handles Python warnings.\n","warnings.filterwarnings(\"ignore\")                # Suppresses all warnings.\n"],"metadata":{"id":"lj17VJbMz4v-","executionInfo":{"status":"ok","timestamp":1736019679075,"user_tz":180,"elapsed":15489,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["#### **Load the Stratified Heterogeneous Graph**"],"metadata":{"id":"0H1GfqQ4iM82"}},{"cell_type":"code","source":["# Load the stratified heterogeneous graph\n","graph_path = '/content/drive/MyDrive/GraphFeatures/StratifiedHeteroGraph/StratifiedHeteronousGraph_AllEdges.pt'\n","hetero_data = torch.load(graph_path)\n","\n","print(f\"Graph Loaded: {hetero_data}\")\n","print(f\"Node features shape: {hetero_data.x.size()}\")\n","print(f\"Edge index shape: {hetero_data.edge_index.size()}\")\n","print(f\"Target labels shape: {hetero_data.y.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EbniSMkG7qhM","executionInfo":{"status":"ok","timestamp":1736019690218,"user_tz":180,"elapsed":3912,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"3cfd1d3a-b00e-4b50-cbf5-506da88a1732"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Graph Loaded: Data(x=[99898, 101], edge_index=[2, 23504013], y=[99898])\n","Node features shape: torch.Size([99898, 101])\n","Edge index shape: torch.Size([2, 23504013])\n","Target labels shape: torch.Size([99898])\n"]}]},{"cell_type":"markdown","source":["#### **Scale Node Features**"],"metadata":{"id":"ZWW64JloncSN"}},{"cell_type":"code","source":["# Scale node features using StandardScaler\n","scaler = StandardScaler()\n","hetero_data.x = torch.tensor(\n","    scaler.fit_transform(hetero_data.x.cpu().numpy()),\n","    dtype=torch.float\n",").to(hetero_data.x.device)  # Ensure the scaled features are on the correct device\n","print(\"Node features scaled successfully.\")"],"metadata":{"id":"eKrKsM_cnmAb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736019695731,"user_tz":180,"elapsed":441,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"e6293a15-d0cb-4eaa-9f0b-4aff358a34b5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Node features scaled successfully.\n"]}]},{"cell_type":"markdown","source":["#### **Train-Val-Test Split**"],"metadata":{"id":"_si5b3ETnvPZ"}},{"cell_type":"code","source":["# Split the nodes into train, validation, and test sets\n","num_nodes = hetero_data.num_nodes\n","train_size = int(0.6 * num_nodes)\n","val_size = int(0.2 * num_nodes)\n","test_size = num_nodes - train_size - val_size\n","\n","# Generate random permutations for shuffling the nodes\n","perm = torch.randperm(num_nodes)\n","train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n","val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n","test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n","\n","train_mask[perm[:train_size]] = True\n","val_mask[perm[train_size:train_size + val_size]] = True\n","test_mask[perm[train_size + val_size:]] = True\n","\n","# Assign the masks to the graph\n","hetero_data.train_mask = train_mask\n","hetero_data.val_mask = val_mask\n","hetero_data.test_mask = test_mask\n","\n","print(\"Train, validation, and test masks created successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R15buX36wSUh","executionInfo":{"status":"ok","timestamp":1736019698636,"user_tz":180,"elapsed":166,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"1a0f2124-5f26-4866-99dc-0dfd033c7592"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Train, validation, and test masks created successfully.\n"]}]},{"cell_type":"markdown","source":["#### **Stratified Heterogenous Graph with GCN model**"],"metadata":{"id":"T4Ll6UiPD88_"}},{"cell_type":"markdown","source":["#### **Define Model**"],"metadata":{"id":"W8fclVYSoklb"}},{"cell_type":"code","source":["class GCNModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GCNModel, self).__init__()\n","        self.conv1 = GCNConv(input_dim, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, output_dim)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv2(x, edge_index)\n","        return x"],"metadata":{"id":"-sVMJiAZorum","executionInfo":{"status":"ok","timestamp":1736019705904,"user_tz":180,"elapsed":248,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["##### **Initialize and Train the Model**"],"metadata":{"id":"QdXhKKgRpmDv"}},{"cell_type":"code","source":["# Model parameters\n","input_dim = hetero_data.x.size(1)  # Feature dimension\n","hidden_dim = 64\n","output_dim = len(torch.unique(hetero_data.y))  # Number of classes\n","\n","model = GCNModel(input_dim, hidden_dim, output_dim)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Move data and model to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","hetero_data = hetero_data.to(device)\n","\n","# Training loop\n","num_epochs = 50\n","best_val_loss = float('inf')\n","patience = 5\n","stopping_counter = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    # Forward pass\n","    out = model(hetero_data.x, hetero_data.edge_index)\n","\n","    # Compute loss on training nodes\n","    loss = criterion(out[hetero_data.train_mask], hetero_data.y[hetero_data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Validation loss\n","    model.eval()\n","    with torch.no_grad():\n","        val_out = model(hetero_data.x, hetero_data.edge_index)\n","        val_loss = criterion(val_out[hetero_data.val_mask], hetero_data.y[hetero_data.val_mask])\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}\")\n","\n","    # Early stopping logic\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        stopping_counter = 0\n","    else:\n","        stopping_counter += 1\n","        if stopping_counter >= patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n"],"metadata":{"id":"biUC70rL0Bk1","executionInfo":{"status":"ok","timestamp":1736019839810,"user_tz":180,"elapsed":131468,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3aacdb4b-6ea8-4892-bad1-85e3a8d6a994"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Training Loss: 0.6965, Validation Loss: 0.7686\n","Epoch 2/50, Training Loss: 0.7691, Validation Loss: 0.7079\n","Epoch 3/50, Training Loss: 0.7084, Validation Loss: 0.6500\n","Epoch 4/50, Training Loss: 0.6503, Validation Loss: 0.6684\n","Epoch 5/50, Training Loss: 0.6689, Validation Loss: 0.6894\n","Epoch 6/50, Training Loss: 0.6902, Validation Loss: 0.6761\n","Epoch 7/50, Training Loss: 0.6772, Validation Loss: 0.6534\n","Epoch 8/50, Training Loss: 0.6545, Validation Loss: 0.6454\n","Epoch 9/50, Training Loss: 0.6465, Validation Loss: 0.6525\n","Epoch 10/50, Training Loss: 0.6536, Validation Loss: 0.6615\n","Epoch 11/50, Training Loss: 0.6625, Validation Loss: 0.6626\n","Epoch 12/50, Training Loss: 0.6635, Validation Loss: 0.6563\n","Epoch 13/50, Training Loss: 0.6570, Validation Loss: 0.6488\n","Early stopping at epoch 13\n"]}]},{"cell_type":"markdown","source":["#### **Evaluate the Model**"],"metadata":{"id":"GplYcEIwrs1c"}},{"cell_type":"code","source":["# Evaluate the model\n","model.eval()\n","with torch.no_grad():\n","    out = model(hetero_data.x, hetero_data.edge_index)\n","    preds = out.argmax(dim=1).cpu().numpy()  # Predicted labels\n","\n","    # Test set evaluation\n","    y_true = hetero_data.y[hetero_data.test_mask].cpu().numpy()\n","    y_pred = preds[hetero_data.test_mask.cpu().numpy()]\n","\n","    # Metrics\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    auc = roc_auc_score(y_true, out[hetero_data.test_mask][:, 1].cpu().numpy())\n","\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1-score: {f1:.4f}\")\n","    print(f\"AUC-ROC: {auc:.4f}\")\n"],"metadata":{"id":"UoQyM1Hh2A4x","executionInfo":{"status":"ok","timestamp":1736019843451,"user_tz":180,"elapsed":3647,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"d39a20f1-b2e5-44a4-e5e2-842ca79e3e6e","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6451\n","Precision: 0.6741\n","Recall: 0.5607\n","F1-score: 0.6122\n","AUC-ROC: 0.6515\n"]}]},{"cell_type":"markdown","source":["#### **Stratified Heterogenous Graph with GAT Model**"],"metadata":{"id":"DNit4aujDg_A"}},{"cell_type":"markdown","source":["#### **Define Model**"],"metadata":{"id":"nY_WqlqgEet4"}},{"cell_type":"code","source":["class GATModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, heads=1):\n","        super(GATModel, self).__init__()\n","        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True)\n","        self.gat2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False)\n","\n","    def forward(self, x, edge_index):\n","        x = self.gat1(x, edge_index)\n","        x = F.elu(x)\n","        x = self.gat2(x, edge_index)\n","        return x"],"metadata":{"id":"Bq2fZ86pD5od","executionInfo":{"status":"ok","timestamp":1736019843452,"user_tz":180,"elapsed":6,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["#### **Initialize and Train Model**"],"metadata":{"id":"38lu4wxhEqFE"}},{"cell_type":"code","source":["# Model parameters\n","input_dim = hetero_data.x.size(1)  # Feature dimension\n","hidden_dim = 64\n","output_dim = len(torch.unique(hetero_data.y))  # Number of classes\n","heads = 8  # Number of attention heads\n","\n","model = GATModel(input_dim, hidden_dim, output_dim, heads=heads)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Move data and model to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","hetero_data = hetero_data.to(device)\n","\n","# Training loop\n","num_epochs = 50\n","best_val_loss = float('inf')\n","patience = 5\n","stopping_counter = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    # Forward pass\n","    out = model(hetero_data.x, hetero_data.edge_index)\n","\n","    # Compute loss on training nodes\n","    loss = criterion(out[hetero_data.train_mask], hetero_data.y[hetero_data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Validation loss\n","    model.eval()\n","    with torch.no_grad():\n","        val_out = model(hetero_data.x, hetero_data.edge_index)\n","        val_loss = criterion(val_out[hetero_data.val_mask], hetero_data.y[hetero_data.val_mask])\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}\")\n","\n","    # Early stopping logic\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        stopping_counter = 0\n","    else:\n","        stopping_counter += 1\n","        if stopping_counter >= patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajMdcV2qEuOk","executionInfo":{"status":"ok","timestamp":1736022872069,"user_tz":180,"elapsed":3028623,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"5a10fed0-8a73-4a3a-ed15-437ec343a2ed"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Training Loss: 1.0115, Validation Loss: 1.8357\n","Epoch 2/50, Training Loss: 1.8339, Validation Loss: 0.9291\n","Epoch 3/50, Training Loss: 0.9310, Validation Loss: 1.2624\n","Epoch 4/50, Training Loss: 1.2597, Validation Loss: 0.8245\n","Epoch 5/50, Training Loss: 0.8254, Validation Loss: 0.8966\n","Epoch 6/50, Training Loss: 0.8993, Validation Loss: 0.7432\n","Epoch 7/50, Training Loss: 0.7466, Validation Loss: 0.7689\n","Epoch 8/50, Training Loss: 0.7744, Validation Loss: 0.7017\n","Epoch 9/50, Training Loss: 0.7025, Validation Loss: 0.6968\n","Epoch 10/50, Training Loss: 0.6948, Validation Loss: 0.6851\n","Epoch 11/50, Training Loss: 0.6820, Validation Loss: 0.7081\n","Epoch 12/50, Training Loss: 0.7059, Validation Loss: 0.6759\n","Epoch 13/50, Training Loss: 0.6744, Validation Loss: 0.6814\n","Epoch 14/50, Training Loss: 0.6829, Validation Loss: 0.6727\n","Epoch 15/50, Training Loss: 0.6754, Validation Loss: 0.6622\n","Epoch 16/50, Training Loss: 0.6638, Validation Loss: 0.6743\n","Epoch 17/50, Training Loss: 0.6748, Validation Loss: 0.6635\n","Epoch 18/50, Training Loss: 0.6639, Validation Loss: 0.6605\n","Epoch 19/50, Training Loss: 0.6611, Validation Loss: 0.6677\n","Epoch 20/50, Training Loss: 0.6687, Validation Loss: 0.6652\n","Epoch 21/50, Training Loss: 0.6660, Validation Loss: 0.6605\n","Epoch 22/50, Training Loss: 0.6609, Validation Loss: 0.6546\n","Epoch 23/50, Training Loss: 0.6549, Validation Loss: 0.6515\n","Epoch 24/50, Training Loss: 0.6519, Validation Loss: 0.6545\n","Epoch 25/50, Training Loss: 0.6548, Validation Loss: 0.6536\n","Epoch 26/50, Training Loss: 0.6535, Validation Loss: 0.6505\n","Epoch 27/50, Training Loss: 0.6499, Validation Loss: 0.6533\n","Epoch 28/50, Training Loss: 0.6522, Validation Loss: 0.6549\n","Epoch 29/50, Training Loss: 0.6538, Validation Loss: 0.6524\n","Epoch 30/50, Training Loss: 0.6513, Validation Loss: 0.6512\n","Epoch 31/50, Training Loss: 0.6503, Validation Loss: 0.6491\n","Epoch 32/50, Training Loss: 0.6485, Validation Loss: 0.6489\n","Epoch 33/50, Training Loss: 0.6487, Validation Loss: 0.6482\n","Epoch 34/50, Training Loss: 0.6484, Validation Loss: 0.6470\n","Epoch 35/50, Training Loss: 0.6477, Validation Loss: 0.6471\n","Epoch 36/50, Training Loss: 0.6479, Validation Loss: 0.6476\n","Epoch 37/50, Training Loss: 0.6481, Validation Loss: 0.6482\n","Epoch 38/50, Training Loss: 0.6483, Validation Loss: 0.6481\n","Epoch 39/50, Training Loss: 0.6479, Validation Loss: 0.6465\n","Epoch 40/50, Training Loss: 0.6465, Validation Loss: 0.6460\n","Epoch 41/50, Training Loss: 0.6462, Validation Loss: 0.6463\n","Epoch 42/50, Training Loss: 0.6465, Validation Loss: 0.6462\n","Epoch 43/50, Training Loss: 0.6462, Validation Loss: 0.6464\n","Epoch 44/50, Training Loss: 0.6460, Validation Loss: 0.6464\n","Epoch 45/50, Training Loss: 0.6457, Validation Loss: 0.6466\n","Early stopping at epoch 45\n"]}]},{"cell_type":"markdown","source":["#### **Evaluate Model**"],"metadata":{"id":"NdQUvbtAE9o_"}},{"cell_type":"code","source":["# Evaluate the model\n","model.eval()\n","with torch.no_grad():\n","    out = model(hetero_data.x, hetero_data.edge_index)\n","    preds = out.argmax(dim=1).cpu().numpy()  # Predicted labels\n","\n","    # Test set evaluation\n","    y_true = hetero_data.y[hetero_data.test_mask].cpu().numpy()\n","    y_pred = preds[hetero_data.test_mask.cpu().numpy()]\n","\n","    # Metrics\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    auc = roc_auc_score(y_true, out[hetero_data.test_mask][:, 1].cpu().numpy())\n","\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1-score: {f1:.4f}\")\n","    print(f\"AUC-ROC: {auc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"euTk83ZtFBFq","executionInfo":{"status":"ok","timestamp":1736022892821,"user_tz":180,"elapsed":20755,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"c5218697-ca0c-4eab-ce2e-9d1417e4a046"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6448\n","Precision: 0.6837\n","Recall: 0.5376\n","F1-score: 0.6019\n","AUC-ROC: 0.5969\n"]}]},{"cell_type":"markdown","source":["#### **Stratified Heterogenous Graph with GraphSAGE Model**"],"metadata":{"id":"3CcPl_1kIebC"}},{"cell_type":"markdown","source":["#### **Define Model**"],"metadata":{"id":"ZgeJbGO7IoK8"}},{"cell_type":"code","source":["class GraphSAGEModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GraphSAGEModel, self).__init__()\n","        self.sage1 = SAGEConv(input_dim, hidden_dim)\n","        self.sage2 = SAGEConv(hidden_dim, output_dim)\n","\n","    def forward(self, x, edge_index):\n","        x = self.sage1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.sage2(x, edge_index)\n","        return x\n"],"metadata":{"id":"v1j9W4ZlIsOI","executionInfo":{"status":"ok","timestamp":1736022892821,"user_tz":180,"elapsed":2,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["#### **Initialize and Train Model**"],"metadata":{"id":"bFBlIE85Is1F"}},{"cell_type":"code","source":["# Model parameters\n","input_dim = hetero_data.x.size(1)  # Feature dimension\n","hidden_dim = 64\n","output_dim = len(torch.unique(hetero_data.y))  # Number of classes\n","\n","model = GraphSAGEModel(input_dim, hidden_dim, output_dim)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Move data and model to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","hetero_data = hetero_data.to(device)\n","\n","# Training loop\n","num_epochs = 50\n","best_val_loss = float('inf')\n","patience = 5\n","stopping_counter = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    # Forward pass\n","    out = model(hetero_data.x, hetero_data.edge_index)\n","\n","    # Compute loss on training nodes\n","    loss = criterion(out[hetero_data.train_mask], hetero_data.y[hetero_data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Validation loss\n","    model.eval()\n","    with torch.no_grad():\n","        val_out = model(hetero_data.x, hetero_data.edge_index)\n","        val_loss = criterion(val_out[hetero_data.val_mask], hetero_data.y[hetero_data.val_mask])\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}\")\n","\n","    # Early stopping logic\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        stopping_counter = 0\n","    else:\n","        stopping_counter += 1\n","        if stopping_counter >= patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSmblvLuIzGi","executionInfo":{"status":"ok","timestamp":1736023347386,"user_tz":180,"elapsed":454567,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"f2341a8b-9418-4d61-bef3-afe843f1648a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Training Loss: 0.7223, Validation Loss: 0.6191\n","Epoch 2/50, Training Loss: 0.6180, Validation Loss: 0.5980\n","Epoch 3/50, Training Loss: 0.5957, Validation Loss: 0.5591\n","Epoch 4/50, Training Loss: 0.5560, Validation Loss: 0.5249\n","Epoch 5/50, Training Loss: 0.5213, Validation Loss: 0.5069\n","Epoch 6/50, Training Loss: 0.5033, Validation Loss: 0.4939\n","Epoch 7/50, Training Loss: 0.4906, Validation Loss: 0.4777\n","Epoch 8/50, Training Loss: 0.4747, Validation Loss: 0.4605\n","Epoch 9/50, Training Loss: 0.4576, Validation Loss: 0.4465\n","Epoch 10/50, Training Loss: 0.4433, Validation Loss: 0.4346\n","Epoch 11/50, Training Loss: 0.4308, Validation Loss: 0.4213\n","Epoch 12/50, Training Loss: 0.4168, Validation Loss: 0.4058\n","Epoch 13/50, Training Loss: 0.4007, Validation Loss: 0.3896\n","Epoch 14/50, Training Loss: 0.3842, Validation Loss: 0.3745\n","Epoch 15/50, Training Loss: 0.3693, Validation Loss: 0.3598\n","Epoch 16/50, Training Loss: 0.3554, Validation Loss: 0.3446\n","Epoch 17/50, Training Loss: 0.3405, Validation Loss: 0.3288\n","Epoch 18/50, Training Loss: 0.3249, Validation Loss: 0.3141\n","Epoch 19/50, Training Loss: 0.3102, Validation Loss: 0.3005\n","Epoch 20/50, Training Loss: 0.2964, Validation Loss: 0.2854\n","Epoch 21/50, Training Loss: 0.2813, Validation Loss: 0.2684\n","Epoch 22/50, Training Loss: 0.2641, Validation Loss: 0.2522\n","Epoch 23/50, Training Loss: 0.2476, Validation Loss: 0.2379\n","Epoch 24/50, Training Loss: 0.2332, Validation Loss: 0.2231\n","Epoch 25/50, Training Loss: 0.2185, Validation Loss: 0.2072\n","Epoch 26/50, Training Loss: 0.2029, Validation Loss: 0.1922\n","Epoch 27/50, Training Loss: 0.1878, Validation Loss: 0.1770\n","Epoch 28/50, Training Loss: 0.1727, Validation Loss: 0.1613\n","Epoch 29/50, Training Loss: 0.1575, Validation Loss: 0.1471\n","Epoch 30/50, Training Loss: 0.1436, Validation Loss: 0.1344\n","Epoch 31/50, Training Loss: 0.1310, Validation Loss: 0.1223\n","Epoch 32/50, Training Loss: 0.1188, Validation Loss: 0.1113\n","Epoch 33/50, Training Loss: 0.1077, Validation Loss: 0.1012\n","Epoch 34/50, Training Loss: 0.0975, Validation Loss: 0.0916\n","Epoch 35/50, Training Loss: 0.0879, Validation Loss: 0.0830\n","Epoch 36/50, Training Loss: 0.0794, Validation Loss: 0.0749\n","Epoch 37/50, Training Loss: 0.0715, Validation Loss: 0.0672\n","Epoch 38/50, Training Loss: 0.0637, Validation Loss: 0.0604\n","Epoch 39/50, Training Loss: 0.0570, Validation Loss: 0.0544\n","Epoch 40/50, Training Loss: 0.0511, Validation Loss: 0.0489\n","Epoch 41/50, Training Loss: 0.0458, Validation Loss: 0.0440\n","Epoch 42/50, Training Loss: 0.0411, Validation Loss: 0.0396\n","Epoch 43/50, Training Loss: 0.0370, Validation Loss: 0.0356\n","Epoch 44/50, Training Loss: 0.0331, Validation Loss: 0.0322\n","Epoch 45/50, Training Loss: 0.0298, Validation Loss: 0.0292\n","Epoch 46/50, Training Loss: 0.0269, Validation Loss: 0.0265\n","Epoch 47/50, Training Loss: 0.0243, Validation Loss: 0.0241\n","Epoch 48/50, Training Loss: 0.0221, Validation Loss: 0.0219\n","Epoch 49/50, Training Loss: 0.0201, Validation Loss: 0.0200\n","Epoch 50/50, Training Loss: 0.0183, Validation Loss: 0.0183\n"]}]},{"cell_type":"markdown","source":["#### **Evaluate Model**"],"metadata":{"id":"meEQtkrFIzwc"}},{"cell_type":"code","source":["# Evaluate the model\n","model.eval()\n","with torch.no_grad():\n","    out = model(hetero_data.x, hetero_data.edge_index)\n","    preds = out.argmax(dim=1).cpu().numpy()  # Predicted labels\n","\n","    # Test set evaluation\n","    y_true = hetero_data.y[hetero_data.test_mask].cpu().numpy()\n","    y_pred = preds[hetero_data.test_mask.cpu().numpy()]\n","\n","    # Metrics\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    auc = roc_auc_score(y_true, out[hetero_data.test_mask][:, 1].cpu().numpy())\n","\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1-score: {f1:.4f}\")\n","    print(f\"AUC-ROC: {auc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRRuy8WLI43z","executionInfo":{"status":"ok","timestamp":1736023351196,"user_tz":180,"elapsed":3819,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"37f181e2-71fc-44cd-80a7-a6c17478dbb3"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9991\n","Precision: 0.9986\n","Recall: 0.9997\n","F1-score: 0.9991\n","AUC-ROC: 0.9999\n"]}]},{"cell_type":"markdown","source":["#### **Stratified Heterogenous Graph with Graphomer Transformer Model**"],"metadata":{"id":"N_0qup3TVCZf"}},{"cell_type":"markdown","source":["##### **Define Model**"],"metadata":{"id":"5G-YhNDeWJXu"}},{"cell_type":"code","source":["class GraphomerModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_heads=4):\n","        super(GraphomerModel, self).__init__()\n","        self.transformer1 = TransformerConv(input_dim, hidden_dim, heads=num_heads)\n","        self.transformer2 = TransformerConv(hidden_dim * num_heads, hidden_dim, heads=num_heads)\n","        self.fc = nn.Linear(hidden_dim * num_heads, output_dim)\n","\n","    def forward(self, x, edge_index):\n","        x = self.transformer1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.transformer2(x, edge_index)\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"igTodX_6VS_O","executionInfo":{"status":"ok","timestamp":1736023351197,"user_tz":180,"elapsed":3,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["##### **Initialize and Train Model**"],"metadata":{"id":"zWXlv5YnWUzy"}},{"cell_type":"code","source":["# Model parameters\n","input_dim = hetero_data.x.size(1)  # Feature dimension\n","hidden_dim = 32\n","output_dim = len(torch.unique(hetero_data.y))  # Number of classes\n","num_heads = 4\n","\n","model = GraphomerModel(input_dim, hidden_dim, output_dim, num_heads)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Early stopping parameters\n","patience = 5\n","best_val_loss = float('inf')\n","stopping_counter = 0\n","\n","# Move data and model to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","hetero_data = hetero_data.to(device)\n","\n","# Training Loop\n","num_epochs = 50\n","patience = 5\n","best_val_loss = float('inf')\n","stopping_counter = 0\n","early_stop = False\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(hetero_data.x, hetero_data.edge_index)\n","    loss = criterion(out[hetero_data.train_mask], hetero_data.y[hetero_data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Validation phase\n","    model.eval()\n","    with torch.no_grad():\n","        val_out = model(hetero_data.x, hetero_data.edge_index)\n","        val_loss = criterion(val_out[hetero_data.val_mask], hetero_data.y[hetero_data.val_mask])\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}\")\n","\n","    # Early stopping logic\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        stopping_counter = 0\n","    else:\n","        stopping_counter += 1\n","        if stopping_counter >= patience:\n","            early_stop = True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1z1Q77Ib5aa","executionInfo":{"status":"ok","timestamp":1736027019896,"user_tz":180,"elapsed":3668701,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"f9dcd53e-4d15-4c95-9904-177563ed609a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Training Loss: 0.7485, Validation Loss: 1.1063\n","Epoch 2/50, Training Loss: 1.1138, Validation Loss: 0.6731\n","Epoch 3/50, Training Loss: 0.6743, Validation Loss: 0.6115\n","Epoch 4/50, Training Loss: 0.6102, Validation Loss: 0.5757\n","Epoch 5/50, Training Loss: 0.5751, Validation Loss: 0.5704\n","Epoch 6/50, Training Loss: 0.5717, Validation Loss: 0.5205\n","Epoch 7/50, Training Loss: 0.5223, Validation Loss: 0.4696\n","Epoch 8/50, Training Loss: 0.4696, Validation Loss: 0.4539\n","Epoch 9/50, Training Loss: 0.4530, Validation Loss: 0.4352\n","Epoch 10/50, Training Loss: 0.4346, Validation Loss: 0.3934\n","Epoch 11/50, Training Loss: 0.3923, Validation Loss: 0.3551\n","Epoch 12/50, Training Loss: 0.3538, Validation Loss: 0.3297\n","Epoch 13/50, Training Loss: 0.3252, Validation Loss: 0.2888\n","Epoch 14/50, Training Loss: 0.2805, Validation Loss: 0.2566\n","Epoch 15/50, Training Loss: 0.2460, Validation Loss: 0.2067\n","Epoch 16/50, Training Loss: 0.1949, Validation Loss: 0.1667\n","Epoch 17/50, Training Loss: 0.1566, Validation Loss: 0.1247\n","Epoch 18/50, Training Loss: 0.1157, Validation Loss: 0.0873\n","Epoch 19/50, Training Loss: 0.0827, Validation Loss: 0.0630\n","Epoch 20/50, Training Loss: 0.0575, Validation Loss: 0.0510\n","Epoch 21/50, Training Loss: 0.0437, Validation Loss: 0.0381\n","Epoch 22/50, Training Loss: 0.0329, Validation Loss: 0.0272\n","Epoch 23/50, Training Loss: 0.0211, Validation Loss: 0.0188\n","Epoch 24/50, Training Loss: 0.0135, Validation Loss: 0.0170\n","Epoch 25/50, Training Loss: 0.0126, Validation Loss: 0.0153\n","Epoch 26/50, Training Loss: 0.0099, Validation Loss: 0.0139\n","Epoch 27/50, Training Loss: 0.0082, Validation Loss: 0.0123\n","Epoch 28/50, Training Loss: 0.0069, Validation Loss: 0.0098\n","Epoch 29/50, Training Loss: 0.0041, Validation Loss: 0.0077\n","Epoch 30/50, Training Loss: 0.0028, Validation Loss: 0.0073\n","Epoch 31/50, Training Loss: 0.0029, Validation Loss: 0.0057\n","Epoch 32/50, Training Loss: 0.0020, Validation Loss: 0.0053\n","Epoch 33/50, Training Loss: 0.0015, Validation Loss: 0.0051\n","Epoch 34/50, Training Loss: 0.0018, Validation Loss: 0.0045\n","Epoch 35/50, Training Loss: 0.0012, Validation Loss: 0.0033\n","Epoch 36/50, Training Loss: 0.0010, Validation Loss: 0.0033\n","Epoch 37/50, Training Loss: 0.0011, Validation Loss: 0.0037\n","Epoch 38/50, Training Loss: 0.0007, Validation Loss: 0.0060\n","Epoch 39/50, Training Loss: 0.0008, Validation Loss: 0.0069\n","Epoch 40/50, Training Loss: 0.0011, Validation Loss: 0.0077\n","Epoch 41/50, Training Loss: 0.0007, Validation Loss: 0.0082\n","Epoch 42/50, Training Loss: 0.0003, Validation Loss: 0.0090\n","Epoch 43/50, Training Loss: 0.0005, Validation Loss: 0.0100\n","Epoch 44/50, Training Loss: 0.0003, Validation Loss: 0.0118\n","Epoch 45/50, Training Loss: 0.0003, Validation Loss: 0.0110\n","Epoch 46/50, Training Loss: 0.0003, Validation Loss: 0.0112\n","Epoch 47/50, Training Loss: 0.0003, Validation Loss: 0.0112\n","Epoch 48/50, Training Loss: 0.0003, Validation Loss: 0.0110\n","Epoch 49/50, Training Loss: 0.0002, Validation Loss: 0.0108\n","Epoch 50/50, Training Loss: 0.0003, Validation Loss: 0.0107\n"]}]},{"cell_type":"markdown","source":["##### **Evaluate Model**"],"metadata":{"id":"sGoPPAIgZuS_"}},{"cell_type":"code","source":["# Evaluate the model\n","model.eval()\n","with torch.no_grad():\n","    out = model(hetero_data.x, hetero_data.edge_index)\n","    preds = out.argmax(dim=1).cpu().numpy()  # Predicted labels\n","\n","    # Test set evaluation\n","    y_true = hetero_data.y[hetero_data.test_mask].cpu().numpy()\n","    y_pred = preds[hetero_data.test_mask.cpu().numpy()]\n","\n","    # Metrics\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    auc = roc_auc_score(y_true, out[hetero_data.test_mask][:, 1].cpu().numpy())\n","\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1-score: {f1:.4f}\")\n","    print(f\"AUC-ROC: {auc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZMTbPmqOa4_z","executionInfo":{"status":"ok","timestamp":1736027045492,"user_tz":180,"elapsed":25599,"user":{"displayName":"Samuel Effiom","userId":"12165818408518423394"}},"outputId":"507607b9-e743-4319-f910-1ed873634532"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9994\n","Precision: 0.9996\n","Recall: 0.9992\n","F1-score: 0.9994\n","AUC-ROC: 1.0000\n"]}]}]}