The increasing sophistication and global scale of financial fraud demand advanced detection methodologies that surpass traditional machine learning models. This project explores the transformative potential of Graph Neural Networks (GNNs) and transformer-based architectures, such as Graphormer, in fraud detection. 

By systematically evaluating various graph construction techniques—node-centric, edge-centric, stratified heterogeneous, and temporal representations—this research investigates their impact on model performance. The study leverages the IEEE-CIS fraud detection dataset, enriched through feature engineering, to construct graph representations capturing the complex yet relational nature of financial transactions. Traditional GNN models, including Graph Convolutional Networks (GCN), Graph Attention Networks (GAT), and GraphSAGE, are benchmarked against Graphormer to assess scalability, accuracy, and the ability to model intricate fraud patterns. 

Results highlight the superiority of transformer-based architectures in capturing long-range dependencies and adapting to dynamic fraud patterns, offering a significant advancement in graph-based fraud detection. The findings not only optimize fraud detection frameworks but also establish a foundation for applications in cybersecurity, social network analysis, and recommendation systems.
